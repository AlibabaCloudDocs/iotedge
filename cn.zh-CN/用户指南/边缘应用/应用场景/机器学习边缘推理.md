# 机器学习边缘推理

Link IoT Edge支持以边缘应用的方式，将云端的机器学习模型部署到边缘端，并在边缘端执行机器学习推理（ML Inference） 。此功能非常适用于在边缘端处理实时性强、数据量大的服务（例如计算机视觉识别）。

-   在树莓派4B（Raspberry Pi 4B）或树莓派3B/B+（Raspberry Pi 3B/B+）系统上安装并启动Link IoT Edge软件包，具体操作请参见[基于树莓派搭建环境](/cn.zh-CN/用户指南/环境搭建/标准版环境搭建/基于树莓派搭建环境.md)。
-   在您的树莓派上连接好摄像头，具体操作请参见[树莓派摄像头安装指南](https://www.raspberrypi.org/documentation/usage/camera/)。

您可以在[阿里云机器学习平台PAI](https://data.aliyun.com/product/learn)或者任何其它地方训练您的推理模型，把训练好的模型和相关代码托管在阿里云的函数计算、对象存储（Object Storage Service，OSS）或者容器镜像（Container Registry）等服务中， 然后在Link IoT Edge边缘实例中以边缘应用的方式，将模型部署到网关。在网关上使用本地模型执行推理后把结果上传到阿里云物联网平台。

![Link IoT Edge ML Inference工作原理](https://static-aliyun-doc.oss-cn-hangzhou.aliyuncs.com/assets/img/zh-CN/4443699851/p87657.png)

本文通过在树莓派4B上部署基于Tensorflow Lite的深度学习Object Detection（目标检测）模型，讲述如何在Link IoT Edge上使用机器学习推理。

## 一、配置树莓派并安装边缘推理运行时

使用SSH工具连接到树莓派终端，执行如下步骤中的命令。

1.  打开树莓派配置工具，并使能摄像头。

    1.  执行如下命令，打开树莓派配置工具。

        ```
        sudo raspi-config
        ```

    2.  根据界面提示，选择Interfacing Options，单击**Select**。

        ![Interfacing Options](https://static-aliyun-doc.oss-cn-hangzhou.aliyuncs.com/assets/img/zh-CN/4443699851/p87798.png)

    3.  选择Camera，单击**Select**，使能摄像头。

        ![Camera](https://static-aliyun-doc.oss-cn-hangzhou.aliyuncs.com/assets/img/zh-CN/4443699851/p87804.png)

    4.  根据界面提示，单击**Finish**后，重启树莓派。

    5.  在树莓派shell终端执行下面的命令，使用树莓派自带raspistill工具测试摄像头是否正常工作。

        该命令将在树莓派终端输出摄像头信息，并在当前目录保存名为cam.jpg的图片文件。

        ```
        raspistill -v -o cam.jpg
        ```

2.  安装Tensorflow Lite Interpreter。

    1.  在树莓派Shell终端执行如下命令，下载Tensorflow Lite Interpreter安装包。

        ```
        curl -O https://iotedge-web.oss-cn-shanghai.aliyuncs.com/public/LeMLInterpreter/ARMv7hf/linkedge_ml_tflite_raspi4_cp3x_armv7hf_installer.tar.gz
        ```

    2.  解压并安装软件包。

        ```
        tar xzvf linkedge_ml_tflite_raspi4_cp37_armv7hf_installer.tar.gz 
        cd linkedge_ml_tflite_raspi4_cp37_armv7hf_installer/
        ./le_ml_installer.sh
        ```

        系统显示如下图内容，表示安装Tensorflow Lite Interpreter成功。

        ![Tensorflow Lite Interpreter安装成功](https://static-aliyun-doc.oss-cn-hangzhou.aliyuncs.com/assets/img/zh-CN/5443699851/p87862.png)


## 二、云端发布检测器设备驱动

1.  下载检测器设备驱动代码包[object\_detector\_driver.zip](https://iotedge-web.oss-cn-shanghai.aliyuncs.com/public/LeMLInterpreter/ARMv7hf/object_detector_driver.zip)。

2.  登录[边缘计算控制台](https://iot.console.aliyun.com/le/instance/list)。

3.  在左侧导航栏，单击**驱动管理**。

4.  添加自研驱动，具体操作请参见[云端发布](/cn.zh-CN/用户指南/设备接入/驱动发布/云端发布.md)。

    其中，部分参数设置如下所示。

    |参数|描述|
    |--|--|
    |驱动名称|自定义驱动的名称，例如obj\_detector\_driver。|
    |通信协议类型|选择自定义。|
    |语言类型|选择Python 3.5。|
    |驱动是否内置|选择否。|
    |驱动文件|单击**上传文件**，上传已下载到本地的[object\_detector\_driver.zip](https://iotedge-web.oss-cn-shanghai.aliyuncs.com/public/LeMLInterpreter/ARMv7hf/object_detector_driver.zip)驱动文件。|
    |驱动版本|设置为v1.0.0。|
    |驱动适配的边缘版本|选择2.4.0 版本及以上。|
    |驱动版本描述|描述您创建的驱动和版本信息，可以为空。|

    其余参数无需配置。


## 三、分配检测器设备驱动到边缘实例

1.  左侧导航栏单击**边缘实例**，在本文“前提条件”中已创建的边缘实例右侧，单击**查看**。

2.  在**实例详情**页面设备与驱动页签，单击**全部驱动**右侧的`+`图标 。

3.  在分配驱动页面中，选择**自研驱动**，单击obj\_detector\_driver驱动对应操作栏中的**分配**。然后单击**关闭**。

    ![分配检测器设备驱动](https://static-aliyun-doc.oss-cn-hangzhou.aliyuncs.com/assets/img/zh-CN/4828420061/p87932.png)

4.  单击**分配子设备**，在obj\_detector\_driver驱动下，为边缘实例添加子设备。

    ![边缘推理-分配子设备](https://static-aliyun-doc.oss-cn-hangzhou.aliyuncs.com/assets/img/zh-CN/4828420061/p87933.png)

5.  在添加设备对话框中，单击**新建产品**，创建检测器产品。

    ![边缘推理-创建产品](https://static-aliyun-doc.oss-cn-hangzhou.aliyuncs.com/assets/img/zh-CN/5443699851/p87934.png)

    在创建产品对话框中设置参数后，单击**完成**。

    |参数|描述|
    |--|--|
    |产品名称|此处设置为detector。|
    |所属品类|选择品类，为该产品定义[物模型](/cn.zh-CN/设备管理/物模型/什么是物模型.md)。此处选择**自定义品类**。|
    |接入网关协议|此处选择自定义。|

6.  在添加设备对话框，产品自动分配已创建的产品，单击产品下的前往配置，为产品添加自定义功能。具体操作和参数说明请参见[单个添加物模型](/cn.zh-CN/设备管理/物模型/单个添加物模型.md)。

    设置如下图两种属性。

    -   物体类别属性

        ![物体类别属性](https://static-aliyun-doc.oss-cn-hangzhou.aliyuncs.com/assets/img/zh-CN/5443699851/p87935.png)

    -   检测得分属性

        ![检测得分属性](https://static-aliyun-doc.oss-cn-hangzhou.aliyuncs.com/assets/img/zh-CN/6443699851/p87953.png)

7.  返回[边缘计算控制台](https://iot.console.aliyun.com/le/instance/list)实例详情页面**添加设备**对话框，为detector产品添加设备。

    ![添加tflite_detector设备](https://static-aliyun-doc.oss-cn-hangzhou.aliyuncs.com/assets/img/zh-CN/6443699851/p87967.png)

8.  将新建的tflite\_detector设备分配到边缘实例。


## 四、创建边缘推理函数

1.  下载边缘推理函数代码包[object\_detector\_app.zip](https://iotedge-web.oss-cn-shanghai.aliyuncs.com/public/LeMLInterpreter/ARMv7hf/object_detector_app.zip)。

2.  登录阿里云[函数计算控制台](https://fc.console.aliyun.com/)。

    如尚未开通该服务，请阅读并勾选**我已阅读并同意**内容，单击**立即开通**，开通服务。

3.  （可选）左侧导航栏单击**服务-函数**，在**新建函数**后的下拉框中选择**新建服务**，根据界面提示配置参数后，单击**创建**创建一个服务。

    其中，**服务名称**必须填写，此处设置为EdgeFC，其余参数可根据您的需求设置，也可以不设置。

    **说明：** 若已操作过其他应用场景示例或小程序示例，即已创建EdgeFC服务，则无需重复创建。

4.  创建服务成功后，在服务-函数页面单击**新建函数**，并使用**事件函数**方式创建函数。

5.  设置边缘推理函数的基础管理配置参数。

    |参数|描述|
    |--|--|
    |所在服务|选择已创建的EdgeFC服务。|
    |函数名称|设置为object\_detector\_app。|
    |运行环境|设置函数的运行环境，此示例中选择python3。|
    |函数入口|使用默认值`index.handler`。|
    |函数执行内存|设置为512 MB。|
    |超时时间|设置为10秒。|
    |实例并发度|保持默认值。|

    其余参数的值请根据您的实际需求设置，也可以不设置。详情请参见[函数计算]()。

    确认函数信息后，单击**完成**。

6.  创建函数完成后，系统自动跳转到函数详情页面。请在**代码执行**页签下选择**代码包上传**，单击**选择文件**，上传步骤1中下载的[object\_detector\_app.zip](https://iotedge-web.oss-cn-shanghai.aliyuncs.com/public/LeMLInterpreter/ARMv7hf/object_detector_app.zip)代码包，然后单击**保存**。

    代码上传成功后，在**在线编辑**框中查看源码。


## 五、分配函数到边缘实例

1.  登录[边缘计算控制台](https://iot.console.aliyun.com/le/instance/list)。

2.  在左侧导航栏单击**应用管理**。

3.  使用本文上方[四、创建边缘推理函数](#section_ici_gdq_mr6)中已创建的函数，创建函数计算类型的边缘应用。具体操作请参见[函数计算应用](/cn.zh-CN/用户指南/边缘应用/新增自研应用/函数计算应用.md)。

    应用信息参数说明如下：

    |参数|描述|
    |--|--|
    |应用名称|设置您应用的名称，例如le\_object\_detector。|
    |应用类型|选择函数计算。|
    |地域|选择您创建的服务所在的地域。|
    |服务|选择EdgeFC服务。|
    |函数|选择object\_detector\_app函数。|
    |授权|选择AliyunIOTAccessingFCRole。|
    |应用版本|设置应用的版本，必须是该应用唯一的版本号，即一个应用不可以设置两个相同的版本号。|

    **函数配置**区域框中，启用默认配置选择是，则其余参数无需设置。

4.  左侧导航栏单击**边缘实例**。

5.  在本文“前提条件”中完成的边缘实例右侧，单击**查看**。

6.  在实例详情页面**边缘应用**页签，单击**分配应用**。

7.  将已创建的边缘推理函数计算应用le\_object\_detector分配到边缘实例中，单击**关闭**。


## 六、部署边缘实例

1.  在实例详情页面，单击右上角**部署**后在弹出对话框中单击**确定**，将子设备、函数计算等资源下发到边缘端。

    您可以通过单击**部署详情**来查看部署进度及结果。

2.  部署完成后，在**设备与驱动**页签，可查到tflite\_detector设备状态变为在线。

3.  单击tflite\_detector设备右侧的**查看**，界面跳转到**设备详情**页面。

4.  在**设备详情**页面**物模型数据** \> **运行状态**页签，查看边缘推理结果。

    放置常见的物体到树莓派摄像头前或人站在摄像头前，函数计算应用le\_object\_detector，会识别物体或人脸并将识别到的结果上报到物联网平台。

    ![边缘推理-运行状态](https://static-aliyun-doc.oss-cn-hangzhou.aliyuncs.com/assets/img/zh-CN/6443699851/p88056.png)

    至此您已经完整地体验了以边缘应用的方式，将机器学习模型部署到边缘端，并在边缘端执行推理的操作。


